---
title: "Computational Musicology Portfolio"
author: "River Vaudrin"
date: "15 February 2021"
output: html_document
---

## Introduction:
Outsider music is a derivative of <a href="https://www.britannica.com/art/outsider-art">outsider art</a>, which is defined as "any work of art produced by an untrained idiosyncratic artist who is typically unconnected to the conventional art world—not by choice but by circumstance." Its defining feature is "the tendency of the artists to be “straight talking” (even if that talk is straight from a radically different worldview)." In 2000, Irwin Chusid conceptualized the term outsider music in his book: Songs in the Key of Z, in which he explores the field of outsider music by highlighting its most prominent artists. Chusid defines outsider music as "crackpot and visionary music, where all trails lead essentially one place: over the edge." The book was accompanied by two compilation albums that featured a variety of outsider musicians. 

These definitions are quite vague, however, I think that we can make it less ambiguous if we look at the differences between outsider musicians and other idiosyncratic musicians that make unconventional music. The first difference is that outsider musicians create unconventional art by circumstance, and not by choice. "By circumstance" can be interpreted in multiple ways. One interpretation is easily noticeable from Chusid's categorization, and that is most of the artists have some kind of mental disorder. Tiny Tim had Asperger's syndrome, Wesley Willis was a schizophrenic, and Daniel Johnson was both schizophrenic and bipolar. In other words, their unconventionality stemmed from their disorders. Another interpretation is exemplified by The Shaggs, they were a band comprised of three teenage sisters in 1968 formed by their father. One day their father received news from his fortune teller mother that his daughters would become famous musicians, even though his daughters didn't have any experience in making music. Although, after hearing this prophecy he withdrew his daughters from school and sold some family belongings to buy his daughters' instruments, and so the band was formed. These kids essentially had no choice than to play music, and their inexperience shines trough on their first album Philosophy of the World. 

Another key difference that sets outsider musicians apart is the amateurish sound of their music. If the definition of an outsider musician is a musician that makes unconventional music by circumstance, then we could consider Beach Boys' Brian Wilson as an outsider musician, as he was, like Daniel Johnson, diagnosed with schizophrenia and bipolar disorder. However, Wilson's music is far more commercially successful than all of the outsider musicians mentioned by Chusid, I think that this is due to the fact that his music doesn't poses an amateurish quality. In summary, his means that the two defining features of outsider music are that it sounds amateuristic, and that it sounds unconventional because of the circumstances the musicians find themselves in. 

My corpus will consist of albums from artists that can be found on the compilation albums of Chusid's Songs in the Key of Z. The goal is to analyze the corpus with metrics provided by Spotify, and determine whether it is possible to categorize these outsider musicians on the basis of these metrics.



## Corpus:
 -  Life In the USA and Canada, by B.J. Snowden
 -  Eilart Is Back, by Eilert Pilram
 -  Rush Hour, Wesley Willis
 -  God Bless Tiny Tim, by Tiny Tim
 -  Philosophy of the World, by The Shaggs
 -  Yip! Jump Music, by Daniel Johnston
 
## Discussion:
I decided to pick these albums mainly because they were created by outsider musicians that were classified as such by the person who introduced the concept of outsider music. However, I chose these particular artists from Chusid's book because I have listened to these albums and I actually find them very enjoyable.   

### Interesting songs
- In Canada, by B.J Snowden
- Suspicious Minds, by Eilert Pilram
- I Wipped Batman's Ass, by Wesley Willis
- Livin' In the Sunlight, Lovin' In the Moon Light, by Tiny Tim
- Who Are Parents?, by The Shaggs 
- The Beatles, by Daniel Johnston

I've highlighted these songs for two reasons, (1) because they all possess a childlike quality, a feature that is often mentioned as a characteristic of outsider music; (2) and because I wanted to examine at least one song of every artist in the corpus in more detail. It will be interesting to see if the childlike quality would in some way be reflected in the metrics, valence and energy could show to be fruitful, as optimism, energy and positivity are common traits of childlike music. It might not be enough to confidently categorize outsider music, but it could be a starting point.
 
### Strengths and limitations of the corpus:
-The artists all have a very unique style of making music.

-All of Wesley Willis' songs have the exact same structure, perhaps this could be valuable, who knows. 

-Eilart Pilram is a Swedish Elvis impersonator, thus his album is entirely comprised of Elvis covers.

+All of the albums have been classified as outsider music, without much debate. Except for that one time that B.J. Snowden criticized Chusid because she felt she did not belong on his list of outsiders.

+Variety in styles might point to some interesting differences between these outsider musicians.


## Code:
### Load libraries 
```{r}
library(tidyverse)
library(spotifyr)
library(ggrepel)


```

### Load dataframes
```{r}
# Load entire discography 
snowden_disc <- get_artist_audio_features("12XwWwI5wcnQySACjbgf2y")
eilert_disc <- get_artist_audio_features("7aS6aXw9eYfVQxCG1RcVEK")
willis_disc <- get_artist_audio_features("50yovZJnAHoy0pBruvFaCR")
tim_disc <- get_artist_audio_features("0Nc79lkTxXLSIIHDB8mqJC")
shaggs_disc <- get_artist_audio_features("5ixdD9E7P9r51AOcSInQbl")
daniel_disc <- get_artist_audio_features("1jeYbk5eqo6wgsQPjLeU5w")

# Create new dataframe with all artists entire discography
disc <- list(snowden_disc, eilert_disc, willis_disc, tim_disc, shaggs_disc, daniel_disc) %>%
  reduce(full_join)


# Load specific albums
snowden_album <- subset(snowden_disc, album_name=="Life in the USA and Canada")
eilert_album <- subset(eilert_disc, album_name=="Eilert Is Back")
willis_album <- subset(willis_disc, album_name=="Rush Hour")
tim_album <- subset(tim_disc, album_name=="God Bless Tiny Tim")
shaggs_album <- subset(shaggs_disc, album_name=="Philosophy of the World" & album_id=="0TzI1YcMAQVdQ4yUZuy7fA")
daniel_album <- subset(daniel_disc, album_name=="Yip Jump Music")

# Create new dataframe with all albums
albums <- list(snowden_album, eilert_album, willis_album, tim_album, shaggs_album, daniel_album) %>%
  reduce(full_join)


# Load specific tracks
snowden_song <- subset(snowden_album, track_name=="In Canada")
eilert_song <- subset(eilert_album, track_name=="Suspicious Minds")
willis_song <- subset(willis_album, track_name=="I Whipped Batman's Ass")
tim_song <- subset(tim_album, track_name=="Livin' in the Sunlight, Lovin' in the Moon Light")
shaggs_song <- subset(shaggs_album, track_name=="Who Are Parents?")
daniel_song <- subset(daniel_album, track_name=="The Beatles")

# Create new dataframe with all songs
songs <- list(snowden_song, eilert_song, willis_song, tim_song, shaggs_song, daniel_song) %>%
  reduce(full_join)
```
### Explorative plots
First I tried to determine the mood (relaxed, happy, angry or sad) of each album. I did this by using the valence and energy parameters. Spotify defines these as:
- Valence: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).
- Energy: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.
These parameters allow us to categorize the mood of each song. Next, if we compute the mean of the songs for each album, we can categorize the mood of each album. The results can be seen below. 

```{r}
mean_valence_energy <- albums %>% 
  group_by(album_name) %>% 
  summarise(artist_name = artist_name,
            album_name = album_name,
            valence = mean(valence),
            energy  = mean(energy))

song_mood_plot <- ggplot(albums, aes(energy, valence, color=artist_name, shape=artist_name)) +
  geom_point(alpha=.45) +
  geom_point(data=mean_valence_energy, size=4) +
  geom_vline(xintercept=0.5, linetype="dotted") +
  geom_hline(yintercept=0.5, linetype="dotted") +
  theme_bw() +
  xlim(0,1) +
  ylim(0,1) +
  labs(
    title = "Song mood (corpus albums)",
    x = "Energy",
    y = "Valence",
    color="Artist Name",
    shape="Artist Name"
  )

song_mood_plot + annotate("text", x=.25, y=.25, label="Sad", alpha=.6) +
                 annotate("text", x=.25, y=.75, label="Relaxed", alpha=.6) +
                 annotate("text", x=.75, y=.25, label="Angry", alpha=.6) +
                 annotate("text", x=.75, y=.75, label="Happy", alpha=.6) 
```
When we look at the results, we can observe that all albums are relatively close to the center of the plot. This means that we cannot confidently match any album to a certain mood. We can only conclude that Tiny Tim's album is less energetic than all of the other albums, and that Wesley Willis' album is more energetic than the other albums. Another interesting finding is that all of the albums are not overly positive or negative, all of the albums have a similar valence centered around 0.5. 

The next step is to examine if these results are consitent over these artists' 
```{r}
mean_valence_energy_disc <- disc %>% 
  group_by(artist_name) %>% 
  summarise(artist_name = artist_name,
            valence = mean(valence),
            energy  = mean(energy))

song_mood_plot <- ggplot(disc, aes(energy, valence, color=artist_name, shape=artist_name)) +
  geom_point(alpha=.25) +
  geom_point(data=mean_valence_energy_disc, size=4) +
  geom_vline(xintercept=0.5, linetype="dotted") +
  geom_hline(yintercept=0.5, linetype="dotted") +
  theme_bw() +
  xlim(0,1) +
  ylim(0,1) +
  labs(
    title = "Song mood (entire discogrophy)",
    x = "Energy",
    y = "Valence",
    color="Artist Name",
    shape="Artist Name"
  )

song_mood_plot + annotate("text", x=.25, y=.25, label="Sad", alpha=.6) +
                 annotate("text", x=.25, y=.75, label="Angry", alpha=.6) +
                 annotate("text", x=.75, y=.25, label="Relaxed", alpha=.6) +
                 annotate("text", x=.75, y=.75, label="Happy", alpha=.6) 
```

```{r}
danceability_valence_energy_albums <- albums %>% 
  group_by(artist_name) %>% 
  summarise(artist_name = artist_name,
            album_name = album_name,
            score = valence + energy + danceability)

ggplot(danceability_valence_energy_albums, aes(x=album_name, y=score, color=artist_name)) + 
    geom_violin() +
    geom_jitter(position=position_jitter(0.15), alpha=0.4) +
    geom_boxplot(alpha=.2, width=.8) +
    ylim(0,3) +
    labs(title = "Album cohesiveness", x="Album name", y="Danceability + Valence + Energy", color="Artist") +
    theme(axis.text.x = element_text(angle=40, hjust=1))

```

```{r}
ggplot(albums, aes(x=album_name, y=speechiness, color=artist_name)) +
  geom_jitter(width=.2) +
  geom_text(aes(label=ifelse(speechiness>.66,as.character(track_name),'')),size=3,hjust=1,vjust=-.5) +
  ylim(0,1) +
  labs(title = "Spoken word songs", x="Album name", y="Speechiness", color="Artist") +
  theme(axis.text.x = element_text(angle=40, hjust=1))

```

```{r}
ggplot(albums, aes(x=album_name, y=instrumentalness, color=artist_name)) +
  geom_jitter(width=.4) +
  geom_text_repel(data=filter(albums, instrumentalness>0.5), aes(label=track_name), size=3) +
  # geom_text(aes(label=ifelse(instrumentalness>.5,as.character(track_name),'')),size=3,hjust=1,vjust=-.5) +
  ylim(0,1) +
  labs(title = "Instrumental songs", x="Album name", y="Instrumentalness", color="Artist") +
  theme(axis.text.x = element_text(angle=40, hjust=1))

```